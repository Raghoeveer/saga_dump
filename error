ERROR:server.server:Exception: Object of type ndarray is not JSON serializable
async def _fetch_bigquery_to_global_dataframe(self, sql_query: str, nl_query: str) -> str:
"""Fetch data from a BigQuery store and store it in a global dataframe.

    Args:
        sql_query (str): The SQL query to be executed on BigQuery.
        nl_query (str): The natural language query to associate with the DataFrame.
    
    Returns:
        str: The formatted SQL query.
    """
    
    sql_query = sql_query.rstrip(';')
    table = "bixby2-analytics-dev.bxb_dataset_ingestion.bxb_unified_dw_copy_raghu"
    logger.info(sql_query)
    
    credentials = service_account.Credentials.from_service_account_file(
        "C:\\Users\\raghu.r\\Saga_using_agents\\central_orchestrator\\agents\\Data_retrieval_agent\\bixby2-analytics-dev-8977decb93b5.json"
    )
    client = bigquery.Client(credentials=credentials, project=credentials.project_id)   
    formatted_query = sql_query.format(TABLE_SRC=table)
    
    # Fetch data from BigQuery
    df = client.query(formatted_query).to_dataframe()
    
    # Prepare the data for the POST request
    data_to_send = df.to_dict(orient='records')  # Convert DataFrame to JSON
    
    # Make an asynchronous POST request to the /set_df_multi endpoint
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:5000/set_df_multi",
            params={"nl_query": nl_query},  # Include the nl_query as a query parameter
            json=data_to_send,  # Send the DataFrame as JSON
            headers={"Content-Type": "application/json"}  # Set the Content-Type header
        )
    
    # Optionally, you can check the response status
    if response.status_code == 200:
        logger.info("DataFrame updated successfully.")
    else:
        logger.error(f"Failed to update DataFrame: {response.status_code} - {response.text}")
    
    return formatted_query




SELECT yyyymmdd, country, COUNT(nltext) AS utterance_count FROM `bixby2-analytics-dev.bxb_dataset_ingestion.bxb_unified_dw_copy_raghu` WHERE yyyymmdd = '2025-04-03' GROUP BY yyyymmdd, country ORDER BY utterance_count DESC
C:\Users\raghu.r\Saga_using_agents\venv\Lib\site-packages\google\cloud\bigquery\table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.
  warnings.warn(
ERROR:server.server:Exception: Object of type date is not JSON serializable






import numpy as np

# Convert all ndarray columns to lists
for col in df.columns:
    if df[col].apply(lambda x: isinstance(x, np.ndarray)).any():
        df[col] = df[col].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)


ERROR:server.server:Exception: Object of type ndarray is not JSON serializable
async def _fetch_bigquery_to_global_dataframe(self, sql_query: str, nl_query: str) -> str:
"""Fetch data from a BigQuery store and store it in a global dataframe.

    Args:
        sql_query (str): The SQL query to be executed on BigQuery.
        nl_query (str): The natural language query to associate with the DataFrame.
    
    Returns:
        str: The formatted SQL query.
    """
    
    sql_query = sql_query.rstrip(';')
    table = "bixby2-analytics-dev.bxb_dataset_ingestion.bxb_unified_dw_copy_raghu"
    logger.info(sql_query)
    
    credentials = service_account.Credentials.from_service_account_file(
        "C:\\Users\\raghu.r\\Saga_using_agents\\central_orchestrator\\agents\\Data_retrieval_agent\\bixby2-analytics-dev-8977decb93b5.json"
    )
    client = bigquery.Client(credentials=credentials, project=credentials.project_id)   
    formatted_query = sql_query.format(TABLE_SRC=table)
    
    # Fetch data from BigQuery
    df = client.query(formatted_query).to_dataframe()
    
    # Prepare the data for the POST request
    data_to_send = df.to_dict(orient='records')  # Convert DataFrame to JSON
    
    # Make an asynchronous POST request to the /set_df_multi endpoint
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:5000/set_df_multi",
            params={"nl_query": nl_query},  # Include the nl_query as a query parameter
            json=data_to_send,  # Send the DataFrame as JSON
            headers={"Content-Type": "application/json"}  # Set the Content-Type header
        )
    
    # Optionally, you can check the response status
    if response.status_code == 200:
        logger.info("DataFrame updated successfully.")
    else:
        logger.error(f"Failed to update DataFrame: {response.status_code} - {response.text}")
    
    return formatted_query




SELECT yyyymmdd, country, COUNT(nltext) AS utterance_count FROM `bixby2-analytics-dev.bxb_dataset_ingestion.bxb_unified_dw_copy_raghu` WHERE yyyymmdd = '2025-04-03' GROUP BY yyyymmdd, country ORDER BY utterance_count DESC
C:\Users\raghu.r\Saga_using_agents\venv\Lib\site-packages\google\cloud\bigquery\table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.
  warnings.warn(
ERROR:server.server:Exception: Object of type date is not JSON serializable






import numpy as np

# Convert all ndarray columns to lists
for col in df.columns:
    if df[col].apply(lambda x: isinstance(x, np.ndarray)).any():
        df[col] = df[col].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)



