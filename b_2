import json
from uuid import uuid4                                 # Used to encode/decode JSON data
import httpx                                # Async HTTP client for making web requests
from httpx_sse import aconnect_sse           # SSE client extension for httpx (now used for streaming)
from typing import Any, AsyncGenerator      # Type hints for flexible input/output

# Import supported request types

from models.request import SendTaskRequest, GetTaskRequest  # Removed CancelTaskRequest

# Base request format for JSON-RPC 2.0

from models.json_rpc import JSONRPCRequest

# Models for task results and agent identity

from models.task import Task, TaskSendParams
from models.agent import AgentCard

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“

# Custom Error Classes

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“

class A2AClientHTTPError(Exception):
â€œâ€â€œRaised when an HTTP request fails (e.g., bad server response)â€â€â€
pass

class A2AClientJSONError(Exception):
â€œâ€â€œRaised when the response is not valid JSONâ€â€â€
pass

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“

# A2AClient: Main interface for talking to an A2A agent

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“

class A2AClient:
def **init**(self, agent_card: AgentCard = None, url: str = None):
â€œâ€â€
Initializes the client using either an agent card or a direct URL.
One of the two must be provided.
â€œâ€â€
if agent_card:
self.url = agent_card.url
self.agent_card = agent_card
elif url:
self.url = url
self.agent_card = None
else:
raise ValueError(â€œMust provide either agent_card or urlâ€)

```
# -------------------------------------------------------------------------
# send_task: Send a new task to the agent (non-streaming)
# -------------------------------------------------------------------------
async def send_task(self, payload: dict[str, Any]) -> Task:

    request = SendTaskRequest(
        id=uuid4().hex,
        params=TaskSendParams(**payload)  # âœ… Proper model wrapping
    )

    print("\nğŸ“¤ Sending JSON-RPC request:")
    print(json.dumps(request.model_dump(), indent=2))

    response = await self._send_request(request)
    return Task(**response["result"])  # âœ… Extract just the 'result' field


# -------------------------------------------------------------------------
# send_task_streaming: Send a new task to the agent with streaming response
# -------------------------------------------------------------------------
async def send_task_streaming(self, payload: dict[str, Any]) -> AsyncGenerator[str, None]:
    """
    Send a task and yield streaming response chunks as they arrive.
    Uses Server-Sent Events (SSE) for real-time streaming.
    """
    request = SendTaskRequest(
        id=uuid4().hex,
        params=TaskSendParams(**payload)
    )

    print("\nğŸ“¤ Sending streaming JSON-RPC request:")
    print(json.dumps(request.model_dump(), indent=2))

    # Check if the agent supports streaming
    if self.agent_card and not self.agent_card.capabilities.streaming:
        # Fallback to regular request if streaming not supported
        task = await self.send_task(payload)
        # Yield the complete response as a single chunk
        for part in task.history[-1].parts:
            if hasattr(part, 'text'):
                yield part.text
        return

    # Use SSE endpoint for streaming
    streaming_url = f"{self.url.rstrip('/')}/stream"
    
    try:
        async with httpx.AsyncClient() as client:
            async with aconnect_sse(
                client, 
                "POST", 
                streaming_url,
                json=request.model_dump(),
                timeout=500
            ) as event_source:
                async for sse_event in event_source.aiter_sse():
                    if sse_event.event == "data":
                        # Parse the SSE data
                        try:
                            data = json.loads(sse_event.data)
                            if "chunk" in data:
                                yield data["chunk"]
                            elif "error" in data:
                                raise A2AClientHTTPError(500, data["error"])
                        except json.JSONDecodeError:
                            # If not JSON, treat as plain text chunk
                            yield sse_event.data
                    elif sse_event.event == "end":
                        break
                    elif sse_event.event == "error":
                        raise A2AClientHTTPError(500, sse_event.data)
                        
    except httpx.HTTPStatusError as e:
        raise A2AClientHTTPError(e.response.status_code, str(e)) from e
    except Exception as e:
        raise A2AClientHTTPError(500, str(e)) from e


# -------------------------------------------------------------------------
# send_task_auto: Automatically choose streaming or non-streaming
# -------------------------------------------------------------------------
async def send_task_auto(self, payload: dict[str, Any], streaming: bool = None) -> AsyncGenerator[str, None]:
    """
    Automatically choose between streaming and non-streaming based on agent capabilities.
    If streaming=True is forced, will attempt streaming even if not advertised.
    """
    # Determine if we should use streaming
    should_stream = streaming
    if should_stream is None:
        should_stream = (self.agent_card and 
                       self.agent_card.capabilities and 
                       self.agent_card.capabilities.streaming)
    
    if should_stream:
        # Use streaming approach
        async for chunk in self.send_task_streaming(payload):
            yield chunk
    else:
        # Use regular approach and yield complete response
        task = await self.send_task(payload)
        for part in task.history[-1].parts:
            if hasattr(part, 'text'):
                yield part.text


# -------------------------------------------------------------------------
# get_task: Retrieve the status or history of a previously sent task
# -------------------------------------------------------------------------
async def get_task(self, payload: dict[str, Any]) -> Task:
    request = GetTaskRequest(params=payload)
    response = await self._send_request(request)
    return Task(**response["result"])


# -------------------------------------------------------------------------
# _send_request: Internal helper to send a JSON-RPC request
# -------------------------------------------------------------------------
async def _send_request(self, request: JSONRPCRequest) -> dict[str, Any]:
    async with httpx.AsyncClient() as client:
        try:
            response = await client.post(
                self.url,
                json=request.model_dump(),  # Convert Pydantic model to JSON
                timeout=500
            )
            response.raise_for_status()     # Raise error if status code is 4xx/5xx
            return response.json()          # Return parsed response as a dict

        except httpx.HTTPStatusError as e:
            raise A2AClientHTTPError(e.response.status_code, str(e)) from e

        except json.JSONDecodeError as e:
            raise A2AClientJSONError(str(e)) from e
```

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“

# Usage Examples

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“

async def example_usage():
â€œâ€â€
Example of how to use the streaming client
â€œâ€â€
# Initialize client
client = A2AClient(url=â€œhttp://localhost:10013â€)

```
# Example 1: Non-streaming (original behavior)
task = await client.send_task({
    "id": "task123",
    "sessionId": "session456",
    "history": [
        {
            "role": "user",
            "parts": [{"text": "Hello, how are you?"}]
        }
    ]
})
print(f"Complete response: {task}")

# Example 2: Streaming response
print("\nğŸŒŠ Streaming response:")
async for chunk in client.send_task_streaming({
    "id": "task124",
    "sessionId": "session456",
    "history": [
        {
            "role": "user", 
            "parts": [{"text": "Tell me a story"}]
        }
    ]
}):
    print(chunk, end='', flush=True)  # Print each chunk as it arrives

# Example 3: Auto-detection based on agent capabilities
print("\nğŸ”„ Auto-detection:")
async for chunk in client.send_task_auto({
    "id": "task125",
    "sessionId": "session456",
    "history": [
        {
            "role": "user",
            "parts": [{"text": "What's the weather like?"}]
        }
    ]
}):
    print(chunk, end='', flush=True)
```
