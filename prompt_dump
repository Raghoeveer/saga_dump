
from env import START_DATE, END_DATE, TABLE_NAME

def get_classification_prompt(nl_text):
    return  f"""
        You are expert in classification. Your job is to classify the user query inside --- ---.
        
        My classification falls under below categories:
        - Search Results: When user wants revelant search in utterance: Examples: 'Show me utterances containing bixby', 'bixby-tv and viv.core', 
        - Big Number: Consider this when user ask about total count. Example: 'show me the user count who uses bixby three times everyday'
        - Trend - Single:
        - Trend - Multi Compare:
        - Categorical Field Graph distribution:
        - Numerical Field Graph Distribution:
        - Top N: This is used when user want total count. Examples: 'Least 10 utterance', 'Top 100 utterance', 'Top 10 client type'
        - Dashboard: Consider this when user want to know analysis, statistics, performance or overview

        Find out the classification which is more suitable for user query mentioned below delimited by triple quotes. 
        ---{nl_text}---

        Please respond with valid json containing:
        - "category": only one classification
        - "reason": for selecting category
        - "short_summary": Description, assuming the resultant data of SQL query for user's natural language. Please dont reason"""

def get_table_fields():
    return f"""
        Below are the table schema of big query table, with type, sample, synonym and its description. Consider it while generating big query.
        *   column name: nltext
            synonyms: user utterance, command
            description: utterance command input by voice-assistant user
            examples: hi bixby, what is the time now
        *   column name: messagespeech
            synonyms: response, NLG, reply, output
            description: Text response by voice-assistant for input utterance
            examples: hello, It's twenty past eleven
        *   column name: yyyymmdd
            synonyms: date, local date, today, yesterday, last month
            description: Date of user utterance in format "yyyymmdd"
            examples: 20230101, 20231030
        *   column name: language
            synonyms: locale, Dialect, speech
            description: It's a combination of a ISO language code ("en" for English) and a ISO country code ("IN" for India) used by user for utterance. 
            examples: en-IN, ko-KR, en-GB, en-GB
        *   column name: country
            synonyms: nation
            description: ISO country codes where user registered for using voice-assistant
            examples: IN - India, US - United States of America, KR - Korea
        *   column name: capsuleid
            synonyms: capsule, application
            description: Application ID to which NLU engine classified utterance text based on intent analysis
            examples: viv.core, viv.spotify, viv.phoneApp, viv.clockApp, viv.messageApp, viv.bixbyChat_EN, viv.systemApp, samsung.tvControl, samsung.tvSettings, samsung.tvMediaControl, viv.reminderApp, bixby.watchLauncher, viv.samsungMusicApp, viv.calculator, viv.watchBattery, viv.samsungHealthApp, samsung.fridgeInternet, samsung.tvVoiceInteractionSearch, samsung.tvSearchAndPlayApp, samsung.tvLauncher, samsung.tvMusicPlayback_enIN, samsung.tvChannel, bixby.launcher, viv.cameraApp, bixby.settingsApp
        *   column name: goal
            synonyms: capsule intent, capsule method
            description: goal of an utterance for classified capsuleid,it is a individual task which voice assistant performed and we can mention this as a individual feature of the voice assistant.
        *   column name: hashed_userid
            synonyms: unique user, customer, consumer
            description: hashed user ID to which utterance belongs
        *   column name: hashed_deviceid
            synonyms: unique devices
            description: hashed device ID where utterance input was provided
        *   column name: devicemodel
            synonyms: model
            description: this says from which model the utterance is spoken.In side one client-type there will be many device models.
        *   column name: clienttype
            synonyms: client
            description: device client type from where utterance input was provided
            examples: bixby-mobile, bixby-tv, bixby-watch, bixby-fridge
        *   column name: isgibberish
            type: enum string. values - NULL, true, false
            synonyms: Nonsense, rubbish
            description: denotes whether an utterance is gibberish or not
            examples: NULL, true, false
        *   column name: feedback_label
            type: enum string. values - NULL, 0, 1
            synonyms: utterance feedback
            description: utterance feedback label as classified by model classifier (0 means negative feedback, 1 mean positive feedback)
            examples: NULL, 0, 1
        *   column name: launchmethod
            synonyms: Kick-off technique, Initiation process
            description: Method of launching voice assistant on client by user.
            examples: BUILTIN_MIC, WAKEUP, FOLLOWUP, BIXBY_ICON, TEXT, BLUETOOTH, PROMOTION, HINT, SELECT_CAPSULE
        *   column name: e2e
            synonyms: latency, end to end, time taken to complete, Delay
            description: end-to-end latency of utterance in milliseconds
            examples: "1050", "5012", "10001"
        *   column name: asr_engine
            description: ASR engine latency of utterance
            examples: "1050", "5012", "10001"
        *   column name: age
            description: age of user providing utterance
            examples: 28, 100, 18
        *   column name: local_hour
            synonyms: hour, time
            description: hour when utterance was generated in HH format
            examples: 01, 23, 10
        *   column name: user_registration_date
            synonyms: registration date, date of joining
            description: this is date in "yyyymmdd" format when user registered for using voice assistant. This is the date from when user is started using voice assistant.
            examples: 20230910, 20231230
        
        Note to use schema fields:
        * Do not use fields mentioned in schema in big query unless user asks it explicitly.
    """

def get_conversation(original_conversations = []):
    try:
        conversations = original_conversations.copy()
    except Exception as e:
        print("e")
    
    print(conversations)
    if len(conversations) == 0:
        return ""
    
    last_query = conversations.pop()
    print(last_query)
    cons = ""
    for x in conversations:
        cons += f"""
        "user": {x['query']}
        "assistant": {x['response']}
        """
    return f"""
        You are very good at understanding the context of conversation and rephrase user's query according it. User's last query is given inside *** ***
        
        User conversational session is active with you.
        
        Below is the user natural language query and your response:
        {cons}
        
        Rephrase below natural language query according to the context.
        ***{last_query['query']}***
        
        Your job is respond only the repharsed natural query
                
        Below is the example for your reference where "user" is the one who is asking question and "assistant" is you.:
            "user": "show me count of active users in india last month"
            "assistant": "Count of active users in India last month"
            "user": "How about for last two month",
            "assistant": "Last two months' count of active users in India."
            "user": "Korea",
            "assistant": "Count of active users in Korea during the last month"
            "user": "How about latency for bixby tv for above countries",
            "assistant": "Latency for Bixby TV in India and Korea for the last two months."
            "user": "can you give performance for both countries",
            "assistant": "Performance data for both India and Korea."
            "user": "Can you give the performance for firdge in US",
            "assistant": "Analysis for fridge in United States"
            "user": "How about for watch"
            "assistant": "Performance watch in United States"
    """

def get_trend_examples():
    return f"""
        1. Big query provides the trend of utterances for India, showing the number of utterances per day 
            - SELECT yyyymmdd AS date, COUNT(*) AS utterances FROM `{TABLE_NAME}` 
            WHERE country = 'IN' GROUP BY date ORDER BY date
        2. Big query provides a comparison of the average latency trends for India and Korea.
            - SELECT yyyymmdd AS date, AVG(SAFE_CAST(e2e AS FLOAT64)) AS latency FROM `{TABLE_NAME}` WHERE country IN ('IN', 'KR') GROUP BY date ORDER BY date
        3. Big query provides a hourly active users
            - SELECT local_hour as hour, COUNT(DISTINCT hashed_userid) as users from `{TABLE_NAME}`
        4. Big query compares the trend of daily active users for mobile and visual device data across different English locales
            - SELECT yyyymmdd, clienttype, language, COUNT(DISTINCT hashed_userid) as DAU FROM `{TABLE_NAME}` WHERE clienttype IN ('bixby-mobile', 'bixby-tv') AND language IN ('en-IN', 'en-US', 'en-GB') GROUP BY yyyymmdd, clienttype, language ORDER BY yyyymmdd, clienttype, language
        5. Big query compares the global usage trend of all Bixby products by counting the number of utterances per day for each client type.
            - SELECT yyyymmdd AS date, COUNT(*) AS utterances, clienttype FROM `{TABLE_NAME}` WHERE clienttype IN ('bixby-mobile', 'bixby-watch', 'bixby-tv', 'bixby-fridge') GROUP BY date, clienttype ORDER BY date
        6. Big query returns the average e2e latency for Samsung Bixby in India and Korea for the last 60 days
            - SELECT AVG(SAFE_CAST(e2e AS FLOAT64)) as avg_e2e FROM `{TABLE_NAME}` WHERE country IN ('IN', 'KR') AND  PARSE_DATE('%Y%m%d', yyyymmdd) >= DATE_SUB(PARSE_DATE('%Y%m%d','20230501'), INTERVAL 60 DAY)
        7. Big query returns the trend of e2e latency for Samsung Bixby in India and Korea
            - SELECT country, yyyymmdd, ROUND(AVG(SAFE_CAST(e2e AS FLOAT64))) as avg_e2e_latency FROM `{TABLE_NAME}` WHERE (country = 'IN' OR country = 'KR') GROUP BY country, yyyymmdd ORDER BY yyyymmdd
        8. Big query returns the compares the trend of daily active users for the top 5 capsules on Bixby Mobile
            - SELECT yyyymmdd, capsuleid, COUNT(DISTINCT hashed_userid) as DAU FROM `bixby2-analytics-dev.srib.llm_poc2` WHERE clienttype = 'bixby-mobile' and where capsuleid in (select capsuleid, count(*) as count from `bixby2-analytics-dev.srib.llm_poc2` where clienttype='bixby-mobile' GROUP BY capsuleid ORDER BY count desc LIMIT 5) GROUP BY yyyymmdd, capsuleid
        
        Note for trend creation:
        * You have to use 'GROUP BY'. Example:
        i) SELECT nltext, COUNT(*) as count FROM `bixby2-analytics-dev.srib.llm_poc2` WHERE clienttype = 'bixby-mobile' GROUP BY nltext  
        ii) SELECT yyyymmdd, capsuleid, COUNT(DISTINCT hashed_userid) as DAU FROM `bixby2-analytics-dev.srib.llm_poc2` WHERE clienttype = 'bixby-mobile' and where capsuleid in (select capsuleid, count(*) as count from `bixby2-analytics-dev.srib.llm_poc2` where clienttype='bixby-mobile' GROUP BY capsuleid ORDER BY count desc LIMIT 5) GROUP BY yyyymmdd, capsuleid
        """

def get_examples(classification):
    examples = ""
    classification = classification.lower()
    if(classification.find("trend") != -1):
        examples = get_trend_examples()
    elif(classification=="big number"):
        examples = get_big_number_examples()
    elif(classification=="top n"):
        examples = get_topn_examples()
    elif(classification == "numerical field graph distribution"):
        examples = get_numerical_graph_distribution_examples()
    elif(classification == "search results"):
        examples = get_search_results_examples()
    else:
        return ""

    return f"""
        User want to see {classification} as chart.
        
        Below are the basic examples of big query for your references.
        {examples}
    """

def get_big_number_examples():
    return f"""
        1. Big query returns the total number of unique capsules used in the Bixby voice assistant
            - SELECT COUNT(DISTINCT capsuleid) FROM `{TABLE_NAME}`
        2. Big query calculates the number of active users in India from May 1, 2023 to June 10, 2023
            - SELECT COUNT(DISTINCT hashed_userid) as active_users FROM `{TABLE_NAME}` WHERE country = 'IN' AND yyyymmdd BETWEEN '20230501' AND '20230610'
        3. Big query returns the total count of utterances in the last "3" month
            - SELECT COUNT(*) FROM `{TABLE_NAME}` WHERE  PARSE_DATE('%Y%m%d', yyyymmdd) >= DATE_SUB( PARSE_DATE('%Y%m%d','20230501'), INTERVAL 3 MONTH)
        4. Big query returns the count of users who use Bixby at least three times every day
            - SELECT COUNT(DISTINCT hashed_userid) as user_count FROM (SELECT hashed_userid, COUNT(*) as utterance_count FROM `{TABLE_NAME}` GROUP BY hashed_userid, yyyymmdd HAVING utterance_count >= 3)
        5. Big query returns the total count of utterances in the last "2" weeks for core capsule
            - SELECT COUNT(*) FROM `{TABLE_NAME}` WHERE  PARSE_DATE('%Y%m%d', yyyymmdd) >= DATE_SUB( PARSE_DATE('%Y%m%d','20230501'), INTERVAL 2 WEEK) and capsuleid='viv.core'
        6. Big query returns the total count of utterances in the last "10" days for client bixby tv
            - SELECT COUNT(*) FROM `{TABLE_NAME}` WHERE  PARSE_DATE('%Y%m%d', yyyymmdd) >= DATE_SUB( PARSE_DATE('%Y%m%d','20230501'), INTERVAL 10 DAY) and clienttype='bixby-tv'
        7. Big query returns Total number of capsules
            - SELECT COUNT(DISTINCT capsuleid) FROM `{TABLE_NAME}`"""

def get_topn_examples():
    return f"""
        1. Big query for getting the count of top 50 non-gibberish failed utterances
            - SELECT nltext, COUNT(*) as count FROM `{TABLE_NAME}` WHERE isgibberish = 'false' AND feedback_label = '0' GROUP BY nltext ORDER BY count DESC LIMIT 50
        2. Big query retrieves the top 10 negative NLG responses based on feedback label
            - SELECT messagespeech, COUNT(*) as count FROM `{TABLE_NAME}` WHERE feedback_label = '0' GROUP BY messagespeech ORDER BY count DESC LIMIT 10
        3. Big query returns the top 5 client types along with the number of records for each client type from the given date range
            - SELECT clienttype, COUNT(*) as count FROM `{TABLE_NAME}` GROUP BY clienttype ORDER BY count DESC LIMIT 5
        4. Big Query returns top 10 nltext and its total count.
            - SELECT nltext, COUNT(*) as count FROM `{TABLE_NAME}` group by nltext ORDER BY nltext ASC LIMIT 10
        5. Big Query returns least 10 nltext and its total count.
            - SELECT nltext, COUNT(*) as count FROM `{TABLE_NAME}` group by nltext ORDER BY nltext DESC LIMIT 10
        
        Important Note:- Fetch at least 100 records in big query. Example: LIMIT 100"""

def get_numerical_graph_distribution_examples():
    return f"""
        1. Big query returns the average e2e latency for Samsung Bixby in India and Korea
            - SELECT country, ROUND(AVG(SAFE_CAST(e2e AS FLOAT64))) as avg_e2e_latency FROM `{TABLE_NAME}` WHERE (country = 'IN' OR country = 'KR')  GROUP BY country
        2. Big query returns the count of unique user utterances in India and capsule is "viv.core" for english locale
            - SELECT DISTINCT nltext, COUNT(*) as count FROM `{TABLE_NAME}` WHERE country = 'IN' AND capsuleid='viv.core' and language LIKE 'en-%' GROUP BY nltext ORDER BY count DESC"""

def get_search_results_examples():
    return f"""
        1. Big query for utterances containing "bixby" along with client type and capsuleid
            - SELECT nltext, clienttype, capsuleid FROM `{TABLE_NAME}` WHERE LOWER(nltext) LIKE '%bixby%' LIMIT 100
        2. Big query for whose capsule is "viv.core" for english locale
            - SELECT * FROM `{TABLE_NAME}` WHERE capsuleid='viv.core' and language LIKE 'en-%' LIMIT 100
        3. Big query for user utterances for Bixby TV and capsule viv.core for last 10 days
            - SELECT * FROM `{TABLE_NAME}` WHERE capsuleid='viv.core' and clienttype='bixby-tv' and PARSE_DATE('%Y%m%d', yyyymmdd) >= DATE_SUB( PARSE_DATE('%Y%m%d','20230501'), INTERVAL 10 DAY) LIMIT 100
        
        Important Note:- 
        * Limit to 100 records in big query, if user does not ask for records count. Example: LIMIT 100
        * Do not give total count in result. Example: Count(*)
        * If user does not asks for any column to display then use yyyymmdd, nltext, language, country, clienttype, messagespeech, capsuleid, goal, launchmethod columns in same order given. Example: SELECT yyyymmdd, nltext, language, country, clienttype, messagespeech, capsuleid, goal, launchmethod from"""

def get_abbreviations():
    return f"""
        Below are the commonly used abbreviations:
        * VD: Visual Device, TV (client type: bixby-tv)
        * DA: Digital Appliance, Fridge, AC, Washing Machine (clienttype: bixby-fridge, bixby-appliance)
        * p95: 95th percentile (Format - p[nth percentile])
        * p50: 50th percentile, median
        * Active user: any user having at least 1 utterance in a specified time period
        * DAU: Daily active users
        * MAU: Monthly active users based on month_of_year
        * WAU: Weekly active users based on week_of_year
        * TopN: Top N results based on frequency of a given field
        * English Utterance: Utterances with English locale
    """

def get_additional_info(startDate = None, endDate = None):
    info = f"""
        Additional Information to use while generating big query:
        * Dont consider case while using LIKE. 
        * If date filter not stated, then don’t apply date filter
        * For Top N and Search results, if user does not for any number of records, by default limit to 100 records.
        * For mathematical operations like AVG, SUM etc, use "group by" and then SAFE_CAST it to float64 and also add IFNULL("column_name", "0") before casting it. Example: AVG(SAFE_CAST(e2e AS FLOAT64))
    """
    if(startDate != None and endDate != None):
        info += f"""
        * Data is only available for {startDate} to {endDate}"""
    if(endDate != None):
        info += f"""
        * By default, assume latest date for which data present as {endDate}"""
    return info

def get_dashboard_use_cases(nl_text):
    return f"""
        You are a trained model to generate use cases for dashboard type from user.
        You are job is to give at least 6 use cases which is more suitable for the natural language inside <<< >>>
        
        Our product is: Samsung Bixby
        
        Please use below table schema to generate same:
        {get_table_fields()}
        
        Also consider below Classification as well:
        - Big Number: Consider this when user ask about total count. 
                Example: 'show me the user count who uses bixby three times everyday'
        - Trend - Single:
        - Trend - Multi Compare:
        - Categorical Field Graph distribution:
        - Numerical Field Graph Distribution:
        - Top N: Top “n” number of utterance in count
        
        Below is the natural language to which generate atleast 6 use cases. 
        <<<{nl_text}>>>
        
        Please respond in array format as below:
            - "use_case": Generated use case
            - "category": Classification
    """

def get_final_prompt(nl_query, table, classification):
    try:
        return f"""

            You are big query expert. Your task is to generate a valid big query using natural language provided between >>> <<<

            Table name: {table}
            Table contains data between {START_DATE} AND {END_DATE}. So by default, strictly consider CURRENT_DATE as {END_DATE} while generating big query.
            
            {get_abbreviations()}
            
            {get_table_fields()}
            
            {get_additional_info(START_DATE, END_DATE)}
                    
            {get_examples(classification)}

            Generate big query for below natural language query.
            >>> {nl_query} <<<

            Note:-
            Strictly respond with valid json format, which can be easily parsed in python langauge, containing:
            - "sql_query": 
                {get_sql_example()}
            - "short_summary": Description, assuming the resultant data of SQL query for user's natural language.
            - "operation_type": Operation type used used like "Top N", "Big Number", "Trend - Single", "Trend - Multi Compare", "Categorical Field Graph distribution", "Numerical Field Graph Distribution"
            - "title"
            
            Example: "sql_query": "your generated big query without any special charatcer", "short_summary": "summary you generated", "title": "Title you generated", "operation_type": "Generated operation type"
        """

    
    except Exception as e:
        
        print(e)
        return ""

def get_sql_example():
    return f"""
                Big query should be one liner and format should be like below:
                * SELECT DISTINCT nltext, COUNT(*) as count FROM `{TABLE_NAME}` WHERE country = 'IN' GROUP BY nltext ORDER BY count DESC LIMIT 10
                
                Big query format should not be like below:
                * "SELECT DISTINCT nltext, COUNT(*) as count FROM `{TABLE_NAME}` \\n" +
                    "WHERE country = 'IN' GROUP BY nltext ORDER BY count DESC LIMIT 10"
                * "SELECT DISTINCT nltext, COUNT(*) as count FROM `{TABLE_NAME}` \\
                    WHERE country = 'IN' GROUP BY nltext ORDER BY count DESC LIMIT 10" """


